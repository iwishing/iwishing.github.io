<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>Blog|我所希冀的未来</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="我的脚印">
<meta property="og:type" content="website">
<meta property="og:title" content="Blog|我所希冀的未来">
<meta property="og:url" content="https://github.com/iwishing/myBlog.git/index.html">
<meta property="og:site_name" content="Blog|我所希冀的未来">
<meta property="og:description" content="我的脚印">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Blog|我所希冀的未来">
<meta name="twitter:description" content="我的脚印">
  
    <link rel="alternate" href="/atom.xml" title="Blog|我所希冀的未来" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Blog|我所希冀的未来</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://github.com/iwishing/myBlog.git"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-小科普/为什么判断闰年不能单单看这一年是否为4的倍数" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/18/小科普/为什么判断闰年不能单单看这一年是否为4的倍数/" class="article-date">
  <time datetime="2019-04-18T14:25:13.769Z" itemprop="datePublished">2019-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="为什么判断闰年不能单单看这一年是否为4的倍数"><a href="#为什么判断闰年不能单单看这一年是否为4的倍数" class="headerlink" title="为什么判断闰年不能单单看这一年是否为4的倍数"></a>为什么判断闰年不能单单看这一年是否为4的倍数</h1><h3 id="答："><a href="#答：" class="headerlink" title="答："></a>答：</h3><p>地球绕太阳运行周期为365天5小时48分46秒（合365.24219天）即一回归年。公历的平年只有365日，比回归年短约0.2422 日，所余下的时间约为四年累计一天，故四年于2月加1天，使当年的历年长度为366日，这一年就为闰年。现行公历中每400年有97个闰年。按照每四年一个闰年计算，平均每年就要多算出0.0078天，这样经过四百年就会多算出大约3天来。因此每四百年中要减少三个闰年。所以公历规定：年份是整百数时，必须是400的倍数才是闰年；不是400的倍数的年份，即使是4的倍数也不是闰年。</p>
<h3 id="因此"><a href="#因此" class="headerlink" title="因此"></a>因此</h3><p>我们判断闰年，需要这样写<br><code>year%400 == 0||year%4 == 0&amp;&amp;year%100 != 0</code></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/iwishing/myBlog.git/2019/04/18/小科普/为什么判断闰年不能单单看这一年是否为4的倍数/" data-id="cjumrrnlz000hkktf2t0bl6um" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-大数据学习--小实验" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/18/大数据学习--小实验/" class="article-date">
  <time datetime="2019-04-18T14:03:37.557Z" itemprop="datePublished">2019-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="大数据学习"><a href="#大数据学习" class="headerlink" title="大数据学习"></a>大数据学习</h1><h2 id="–-小实验"><a href="#–-小实验" class="headerlink" title="– 小实验"></a>– 小实验</h2><blockquote>
<blockquote>
<p>环境：<br>idea：ultimate 2018.1<br>系统：windows10 家庭版</p>
</blockquote>
</blockquote>
<h3 id="1-Count计数器"><a href="#1-Count计数器" class="headerlink" title="1.Count计数器"></a>1.Count计数器</h3><p><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--%E5%B0%8F%E5%AE%9E%E9%AA%8C/20190409114549258.png" alt></p>
<h3 id="2-自定义计数器"><a href="#2-自定义计数器" class="headerlink" title="2.自定义计数器"></a>2.自定义计数器</h3><h5 id="1-枚举类型"><a href="#1-枚举类型" class="headerlink" title="(1)枚举类型"></a>(1)枚举类型</h5><p>在mapper中定义<strong>CustomCount</strong>枚举类型<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">enum CustomCount&#123;</span><br><span class="line">            MAP_RUN_COUNT;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></p>
<p>然后在map方法中写<br><code>context.getCounter(CustomCount.MAP_RUN_COUNT).increment(1l);</code><br>后面的increment是增加count值的，参数是1l，参数类型是long<br>计数结果<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--%E5%B0%8F%E5%AE%9E%E9%AA%8C/20190409114918456.png" alt></p>
<h5 id="2-键值对类型"><a href="#2-键值对类型" class="headerlink" title="(2)键值对类型"></a>(2)键值对类型</h5><p>在reducer中定义<br><code>context.getCounter(&quot;REDUCE_RUN_COUNTS&quot;,&quot;running_counts&quot;).increment(1l);</code><br>使用键值对形式定义计数器<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--%E5%B0%8F%E5%AE%9E%E9%AA%8C/20190411010954240.png" alt></p>
<h3 id="3-局部合并"><a href="#3-局部合并" class="headerlink" title="3.局部合并"></a>3.局部合并</h3><p>combiner和reducer的区别在于运行的位置：</p>
<ol>
<li>Combiner是在每一个maptask所在的节点运行</li>
<li>Reducer是接受全局所有Mapper的输出结果</li>
<li>Combiner的意义就是对每一个maptask的输出进行局部汇总，以减少网络传输量</li>
</ol>
<p><strong>具体步骤：</strong></p>
<h5 id="自定义一个Combiner类继承Reducer类，重写reduce方法"><a href="#自定义一个Combiner类继承Reducer类，重写reduce方法" class="headerlink" title="自定义一个Combiner类继承Reducer类，重写reduce方法"></a>自定义一个Combiner类继承Reducer类，重写reduce方法</h5><h5 id="在job中设置-job-setCombinerClass-CustomCombiner-class"><a href="#在job中设置-job-setCombinerClass-CustomCombiner-class" class="headerlink" title="在job中设置:job.setCombinerClass(CustomCombiner.class);"></a>在job中设置:<code>job.setCombinerClass(CustomCombiner.class)</code>;</h5><p><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--%E5%B0%8F%E5%AE%9E%E9%AA%8C/20190411011941037.png" alt><br>这是没有设置Combiner<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--%E5%B0%8F%E5%AE%9E%E9%AA%8C/20190411012753265.png" alt><br>这是设置了Combiner<br>可以明显的看到reduce的输入次数和shuffle过程的字节数有所减少<br><strong><em>注意：求平均值得业务不适用局部聚合，这样会使结果不准确</em></strong></p>
<h3 id="4-对象封装"><a href="#4-对象封装" class="headerlink" title="4.对象封装"></a>4.对象封装</h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/iwishing/myBlog.git/2019/04/18/大数据学习--小实验/" data-id="cjumrrnl0000bkktfcb8rmy4s" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-大数据学习--zookeeper" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/18/大数据学习--zookeeper/" class="article-date">
  <time datetime="2019-04-18T14:03:37.546Z" itemprop="datePublished">2019-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="大数据学习"><a href="#大数据学习" class="headerlink" title="大数据学习"></a>大数据学习</h1><h2 id="–zookeeper"><a href="#–zookeeper" class="headerlink" title="–zookeeper"></a>–zookeeper</h2><blockquote>
<blockquote>
<p>环境：<br>zookeeper：3.4.8<br>系统：centos 6.7</p>
</blockquote>
</blockquote>
<h3 id="1-zookeeper简介"><a href="#1-zookeeper简介" class="headerlink" title="1.zookeeper简介"></a>1.zookeeper简介</h3><h5 id="a-简介"><a href="#a-简介" class="headerlink" title="a.简介"></a>a.简介</h5><p>zookeeper是一个分布式协调服务,是给用户的分布式应用程序提供协调服务的，他的服务目标是分布式程序<br>zookeeper本身就是一个分布式程序，只要有半数以上的节点存活，zk就能正常运行<br>zookeeper所提供的服务有：主从协调、服务器节点动态上下线、统一配置管理、分布式共享锁、统一名称服务等等<br>zookeeper底层实质只提供两个服务：</p>
<ol>
<li>管理(存储，读取)用户程序提交的数据</li>
<li>为用户程序提供数据节点监听服务</li>
</ol>
<h5 id="b-角色描述"><a href="#b-角色描述" class="headerlink" title="b.角色描述"></a>b.角色描述</h5><ol>
<li>Leader：领导者，负责进行投票的发起和决议，更新系统状态</li>
<li>Learner：<ul>
<li>Follower：用于接受客户请求并向客户端返回结果，在选主过程参与投票</li>
<li>Observer：接受用户请求，将请求转发给leader节点，但不参与投票，只同步Leader的状态，增加这个角色目的是为了扩展系统，提高读取速度</li>
</ul>
</li>
<li>Client：请求发起方</li>
</ol>
<p>zookeeper采用的方式是写任意。通过增加机器，他的吞吐能力和响应能力扩展性非常好，而且，随着机器的增多吞吐能力肯定下降(这也是它建立Observer的原因)，而响应能力取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。</p>
<h5 id="c-特性"><a href="#c-特性" class="headerlink" title="c.特性"></a>c.特性</h5><ul>
<li>zookeeper：一个Leader，多个Follower相组成的集群</li>
<li>全局数据一致：每个server保存一份相同的数据副本，client无论连接到哪个server，数据都是一致的</li>
<li>分布式读写：更新请求转发，由Leader实施</li>
<li>更新请求顺序执行：来自同一个client的更新请求按其发送顺序依次执行</li>
<li>数据更新原子性：一次数据更新要么成功，要么失败</li>
<li>实时性：在一定时间范围内，client能读到最新数据</li>
</ul>
<h6 id="Server三种状态"><a href="#Server三种状态" class="headerlink" title="Server三种状态"></a>Server三种状态</h6><p>每个server在工作过程中有三种状态：<br><strong>LOOKING</strong>：当前Server不知道Leader是谁，正在搜寻<br><strong>LEADING</strong>：当前Server即为选举出的Leader<br><strong>FOLLOWING</strong>：leader已经选举出来，当前Server与之同步</p>
<h6 id="zookeeper选举流程"><a href="#zookeeper选举流程" class="headerlink" title="zookeeper选举流程"></a>zookeeper选举流程</h6><p>leader崩溃或者失去大多数follower时，zk进入恢复模式，重新选举出一个新的leader，让所有的server都恢复到一个正确的状态。zk的选举算法有两个：</p>
<ul>
<li>基于basic paxos算法实现</li>
<li>基于fast paxos算法实现</li>
</ul>
<p>系统默认的选举算法为fast paxos算法。</p>
<h5 id="d-zookeeper数据结构"><a href="#d-zookeeper数据结构" class="headerlink" title="d.zookeeper数据结构"></a>d.zookeeper数据结构</h5><p><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190412030737237.png" alt></p>
<ul>
<li>层次化的目录结构，命名符合常规文件系统规范</li>
<li>每个节点在zookeeper中叫做znode，并且其有一个唯一的路径标识</li>
<li>节点Znode可以包含数据和子节点(ephemeral类型节点不能有子节点)</li>
<li>客户端应用可以在节点上设置监视器<blockquote>
<blockquote>
<p>监视器：客户端可以在节点上设置watch，我们叫监视器，当节点状态发生改变的时候，如数据的增、删、改，将会触发监视器，这是，zk会向客户端发送且仅发送一条通知，因为watch只能触发一次，触发后就被销毁了<br>Znode有两种类型</p>
<ul>
<li>短暂(ephemeral):server断开连接时自己删除</li>
<li>持久(persistent)server断开连接不删除</li>
</ul>
<p>Znode有四种形式的目录节点(默认是persistent)</p>
<ul>
<li>PERSISTENT</li>
<li>PERSISTENT_SEQUENTIAL(持久序列/test0000000019)</li>
<li>EPHENERAL</li>
<li>EPHENERAL_SEQUENTIAL<br>创建znode时设置顺序标识，znode名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护。在分布式系统中，顺序号可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序</li>
</ul>
</blockquote>
</blockquote>
</li>
</ul>
<hr>
<h3 id="2-zookeeper的安装与配置"><a href="#2-zookeeper的安装与配置" class="headerlink" title="2.zookeeper的安装与配置"></a>2.zookeeper的安装与配置</h3><p><a href="http://archive.apache.org/dist/zookeeper/" target="_blank" rel="noopener">zookeeper下载地址</a><br>我们下载zookeeper-3.4.8<br>上传，解压到/usr/目录<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190411043446357.png" alt><br><strong>配置</strong><br>首先配置环境变量<br><code>vim /etc/profile</code><br>我们在文件尾加上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ZOOKEEPER_HOME=/usr/zookeeper-3.4.8</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER/bin</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190411043919117.png" alt><br>然后别忘了<code>source /etc/profile</code><br>然后我们需要配置/zookeeper-3.4.8/conf/zoo.cfg文件<br><code>vim /usr/zookeeper-3.4.8/conf/zoo.cfg</code><br>我们在文件末加入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dataDir= /usr/zookeeper-3.4.8/data</span><br><span class="line">dataLogDir= /usr/zookeeper-3.4.8/log</span><br><span class="line">server.1=cbw:2888:3888</span><br><span class="line">server.2=cbw1:2888:3888</span><br><span class="line">server.3=cbw2:2888:3888</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190411050411254.png" alt><br>dataDir有时候zookeeper自带，我们就不需要加，我们加上后面的就行<br><strong><em>注意：cbw：主机名，2888：心跳端口，3888数据端口</em></strong><br>我们只需要修改主机名就行，然后<strong>server.x</strong>这个<strong>x</strong>表示你有多少台服务器，比如我有<strong>3</strong>台，我就要写到<strong>server.3</strong>，然后每个后面的主机名都要改成那台服务器的主机名。<br>之后，我们需要到/usr/zookeeper-3.4.8/目录下创建data和log这两个文件夹，有时候zookeeper自带了data，那么我们只需要创建log文件夹就行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -m 755 data</span><br><span class="line">mkdir -m 755 log</span><br></pre></td></tr></table></figure></p>
<p>然后我们在data目录下创建myid文件,并向其中写入<strong>1</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">touch myid</span><br><span class="line">vim myid</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190411050511388.png" alt><br>最后一步，分发<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp /etc/profile cbw1:/etc</span><br><span class="line">scp -r /usr/zookeeper-3.4.8 cbw1:/usr</span><br></pre></td></tr></table></figure></p>
<p>然后到cbw1这台机上<br><code>source /etc/profile</code><br>并且修改<strong>myid</strong>文件<br><code>vim /usr/zookeeper-3.4.8/data/myid</code><br>修改内容为2，因为我们在zoo.cfg中写的，cbw1对应的是server.2<br>同理cbw2也是要这样写，这样我们zookeeper集群就搭建完毕</p>
<h3 id="3-zookeeper命令"><a href="#3-zookeeper命令" class="headerlink" title="3.zookeeper命令"></a>3.zookeeper命令</h3><p>启动zookeeper服务<br><code>zkServer.sh start</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190411050252384.png" alt><br>查看zookeeper状态<br><code>zkServer.sh status</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190411050157588.png" alt><br>停止zookeeper服务<br><code>zkServer.sh stop</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190411050320751.png" alt><br>连接<br><code>zkCli.sh</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190412034148480.png" alt><br>Create命令<br><code>create [-e] [-s] path data acl</code></p>
<ul>
<li>path指定节点路径</li>
<li>data指定需要存放的数据(状态信息)<br>创建临时节点<br><code>create -e</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190412034346518.png" alt><br><strong><em>注意：临时节点是不能有子节点的</em></strong><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190412034724869.png" alt><br>创建永久节点<br><code>create /zk_test data</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190412035421447.png" alt><br>创建临时有序节点<br><code>create -e -s /zk_test data</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190412035705710.png" alt><br>创建永久有序节点<br><code>create -s /zk_test data</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--zookeeper/20190412035728242.png" alt><br>删除节点<br><code>delete /zk_test</code><br><code>rmr /zk_test</code><br><strong><em>注意：delete不能删除节点下不为空的节点，而rmr可以递归删除</em></strong><br>我们在永久的节点下面创建有序永久节点，如果我们之前在/zk_test下面有3个临时的有序节点，之后客户端断开之后被删除，这个时候你再这个节点创建有序节点的时候，编号不是从0开始，而是从你之前的序号之后开始递增。<h3 id="4-zookeeper-ACL"><a href="#4-zookeeper-ACL" class="headerlink" title="4.zookeeper ACL"></a>4.zookeeper ACL</h3></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/iwishing/myBlog.git/2019/04/18/大数据学习--zookeeper/" data-id="cjumrrnlc000fkktf59m2al8i" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-大数据学习--MapReduce程序编写" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/18/大数据学习--MapReduce程序编写/" class="article-date">
  <time datetime="2019-04-18T14:03:37.537Z" itemprop="datePublished">2019-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="大数据学习"><a href="#大数据学习" class="headerlink" title="大数据学习"></a>大数据学习</h1><h2 id="–MapReduce程序编写"><a href="#–MapReduce程序编写" class="headerlink" title="–MapReduce程序编写"></a>–MapReduce程序编写</h2><blockquote>
<blockquote>
<p>环境：<br>idea: ultimate 2018.1</p>
</blockquote>
</blockquote>
<p>运行流程示意图<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--MapReduce%E7%A8%8B%E5%BA%8F%E7%BC%96%E5%86%99/20190406011925824.png" alt><br>以wordCount为例</p>
<h3 id="Mapper："><a href="#Mapper：" class="headerlink" title="Mapper："></a>Mapper：</h3><p>数据输入进来的第一步，可以定制键值对<br>Mapper类需要继承Mapper父类<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public static class WordCountMapper extends Mapper&lt;LongWritable,Text,Text,IntWritable&gt;&#123;</span><br><span class="line">protected void map(LongWritable key,Text value, Context context) throws IOException, InterrupteException&#123;</span><br><span class="line">        String[] words = value.toString().split(&quot;,&quot;);</span><br><span class="line">        for(String word:words)&#123;</span><br><span class="line">            context.write(new Text(word),new IntWritable(1));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>Mapper</strong>父类一共有4个参数<br>1：是数据的偏移量，例如刚进来为0，第二次进来因为已经读完了一行数据，他就等于第一行数据的长度+0，以此类推<br>2：表示下一行数据，在这个例子里面是一行的字符，也就是下面map方法中的value<br>3：输出的key的数据类型<br>4：这个表示map方法产生的value类型，在我们这个例子中是IntWritable型的，所以我们继承的时候要写IntWritable</p>
<p><strong>map</strong>方法一共有3个参数<br>LongWritable key：偏移量<br>Text value：输入的这行的数据<br>Context：存储map运算后的数据，本例子中<code>context.write(new Text(word),new IntWritable(1))</code>,key是字母，value则为1，因为         字母出现一次就记一次</p>
<h3 id="Reducer："><a href="#Reducer：" class="headerlink" title="Reducer："></a>Reducer：</h3><p>由流程图可以看出这是最后一步，就是总结的作用吧，汇总所有数据，然后进行输出<br>Reducer类需要继承Reducer父类<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public static class HadoopReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">    //相同的key聚合 几种类型的key调用reduce几次</span><br><span class="line">    private IntWritable count = new IntWritable();</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        int sum = 0;</span><br><span class="line">        for (IntWritable value : values) &#123;</span><br><span class="line">            sum += value.get();</span><br><span class="line">        &#125;</span><br><span class="line">        count.set(sum);</span><br><span class="line">        context.write(key, count);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>Reducer</strong>父类一共有4个参数<br>1：输入的key数据类型，本例中是字母，我们用Text存储<br>2：输入的value数据类型，本例中是频率，我们用IntWritable来存储<br>3：输出key的数据类型<br>4：这个表示reduce方法产生的value类型，在我们这个例子中是IntWritable型的，所以我们继承的时候要写IntWritable<br><strong>reduce</strong>方法一共有3个参数<br>Text key：map运算设置的key<br>Iterable<intwritable> value：这是key相同的value的聚合，本例中因为key是字母，value都是1，所以在这里是这样，如，key=a,如                              果里面有3个a，那么这个value中就是{1,1,1}，这个是迭代式的形式<br>Context：存储reduce运算后的数据，本例子中<code>context.write(new Text(word),new IntWritable(1))</code>,key是字母，value则为频          率</intwritable></p>
<h3 id="main方法测试"><a href="#main方法测试" class="headerlink" title="main方法测试"></a>main方法测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Configuration config = new Configuration(); //初始化配置</span><br><span class="line">Job job = Job.getInstance(config);//把任务封装到job对象</span><br><span class="line">job.setJarByClass(HadoopDriver.class);//设置任务启动类</span><br><span class="line">job.setMapperClass(HadoopMapper.class);//设置mapper类</span><br><span class="line">job.setReducerClass(HadoopReducer.class);//设置reducer类</span><br><span class="line"></span><br><span class="line">//设置输出的key和value的数据类型， 如果map的输出和reduce输出key-value类型一致  可以不写map</span><br><span class="line">job.setMapOutputKeyClass(Text.class);</span><br><span class="line">job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">job.setOutputKeyClass(Text.class);</span><br><span class="line">job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">//告诉hadoop集群以什么方式读取数据，从哪里读取</span><br><span class="line">job.setInputFormatClass(TextInputFormat.class);//设置输入格式，默认是key-value输入</span><br><span class="line">TextInputFormat.setInputPaths(job, new Path(&quot;D:\\word.txt&quot;));//设置输入目录，本例也就是需要统计字频的文件</span><br><span class="line"></span><br><span class="line">//告诉hadoop集群以什么样的方式写入数据，数据写入到哪里</span><br><span class="line">job.setOutputFormatClass(TextOutputFormat.class);//设置输出格式，默认是key-value输出</span><br><span class="line">Path path = new Path(&quot;D:\\wordcount&quot;);//新建路径</span><br><span class="line">FileSystem fs = FileSystem.get(config);//新建文件系统</span><br><span class="line">if (fs.exists(path)) &#123;//判断路径是否存在，如果存在则删除，hadoop的严格的容错性保证每次输出一定是新目录</span><br><span class="line">    fs.delete(path, true);</span><br><span class="line">&#125;</span><br><span class="line">TextOutputFormat.setOutputPath(job, path);//设置输出路径</span><br><span class="line">//提交任务</span><br><span class="line">System.exit(job.waitForCompletion(true) ? 0 : 1);//当任务完成时，系统退出</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/iwishing/myBlog.git/2019/04/18/大数据学习--MapReduce程序编写/" data-id="cjumrrnke0006kktf71j9kodv" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-大数据学习--idea与maven的安装与配置" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/18/大数据学习--idea与maven的安装与配置/" class="article-date">
  <time datetime="2019-04-18T14:03:37.527Z" itemprop="datePublished">2019-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="大数据学习"><a href="#大数据学习" class="headerlink" title="大数据学习"></a>大数据学习</h1><h2 id="–idea与maven的安装与配置"><a href="#–idea与maven的安装与配置" class="headerlink" title="–idea与maven的安装与配置"></a>–idea与maven的安装与配置</h2><blockquote>
<blockquote>
<p>环境：<br>idea：ultimate 2018.3<br>maven：3.3.9</p>
</blockquote>
</blockquote>
<h3 id="1-idea的安装与配置"><a href="#1-idea的安装与配置" class="headerlink" title="1.idea的安装与配置"></a>1.idea的安装与配置</h3><p><a href="http://www.jetbrains.com/idea/download/#section=windows" target="_blank" rel="noopener">idea下载地址</a><br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326030342882.png" alt><br>选择ultimate版本下载，这只能免费试用，所有我们需要破解，或者申请资格，我是使用学生身份申请一年的使用权<br><strong>开始安装</strong><br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326010349306.png" alt><br>选择安装位置<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326010524893.png" alt><br>根据自己的电脑配置选择启动器位数，第一个是在桌面创建一个快捷方式，第二个是选择是否在菜单上增加<code>Open Folder as Project</code>功能，<strong>可√可不√</strong>，第三个是创建文件关联，<strong>可以√也可以不√</strong>，第四个如果电脑jdk环境已经配置了，<strong>可以不√</strong>，一般jdk中有jre，第五个是添加启动器目录到路径，<strong>可√可不√</strong><br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326010915397.png" alt><br>下一步，选择开始菜单的文件夹，可以是默认的JetBrains，这样你在开始菜单找J字母，可以找到这个文件夹，里面就有idea<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326011543602.png" alt><br>点击Install，开始安装，等待<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326011626758.png" alt><br>选择重启完成安装<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326012623459.png" alt><br>导入设置文件，但是我们是第一次安装，就选第二个<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326013300882.png" alt><br>同一用户协议<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326013335195.png" alt><br>是否分享数据给JetBrains公司，可以也不可以，自己选择<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326013551923.png" alt><br>设置主题<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326013737527.png" alt><br>选择你要使用的功能，java默认启用了，可以直接下一步<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326013856004.png" alt><br>安装插件，也可以直接下一步<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326013930517.png" alt><br>如果你购买了，可以登录账号，这里我们选择免费试用，只有30天的时间<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326014135892.png" alt><br>到了这一步安装完成了，可以开始使用了<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326014259782.png" alt></p>
<h3 id="2-maven的安装与配置"><a href="#2-maven的安装与配置" class="headerlink" title="2.maven的安装与配置"></a>2.maven的安装与配置</h3><p><a href="https://archive.apache.org/dist/maven/maven-3/" target="_blank" rel="noopener">maven下载地址</a><br>选择相应版本下载， 这里我们选择3.3.9版本<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326022647784.png" alt><br>下载好了后，解压，放到自己选择的文件夹里面，下一步</p>
<h4 id="环境变量的配置"><a href="#环境变量的配置" class="headerlink" title="环境变量的配置"></a>环境变量的配置</h4><p>右键我的电脑<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326023116153.png" alt><br>属性-&gt;高级系统设置<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326023146845.png" alt><br>环境变量<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326023202538.png" alt><br>在系统变量里面新建，然后设置<br><code>MAVEN_HOME= &lt;maven根目录&gt;</code><br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190327093339417.png" alt><br>然后在Path里面新建，写上<br><code>%MAVEN_HOME%\bin</code><br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326023440279.png" alt><br>确定之后，去cmd输入<br><code>mvn -v</code><br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326023638470.png" alt><br>出现这个界面，说明maven配置已经完成</p>
<h4 id="修改资源库"><a href="#修改资源库" class="headerlink" title="修改资源库"></a>修改资源库</h4><p>maven会自动给你下载所需要的jar包， 他默认是从apach的仓库下载，这里我们可以修改仓库，用阿里云或者其他近一点的仓库，这样下载速度会快一些，提高我们的工作效率<br>进入maven根目录<br><code>maven-&gt;conf-&gt;setting.xml</code></p>
<blockquote>
<blockquote>
<p>这个文件要用notepad，或者其他编辑器打开，如果用记事本，里面的东西会很密集，这让修改起来会异常麻烦</p>
</blockquote>
</blockquote>
<p>我们找到<strong>mirrors</strong>标签，写入以下代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;mirror&gt;</span><br><span class="line">    &lt;id&gt;alimaven&lt;/id&gt;</span><br><span class="line">     &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;</span><br><span class="line">     &lt;name&gt;aliyun maven&lt;/name&gt;</span><br><span class="line">     &lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/central/&lt;/url&gt;</span><br><span class="line">&lt;/mirror&gt;</span><br></pre></td></tr></table></figure></p>
<p><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8Emaven%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190326030131047.png" alt><br>这代表我们从阿里云的maven仓库下载jar包，修改完成保存退出。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/iwishing/myBlog.git/2019/04/18/大数据学习--idea与maven的安装与配置/" data-id="cjumrrnki0009kktfk6c4fe2d" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-大数据学习--idea上运行WordCount程序" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/18/大数据学习--idea上运行WordCount程序/" class="article-date">
  <time datetime="2019-04-18T14:03:37.517Z" itemprop="datePublished">2019-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="大数据学习"><a href="#大数据学习" class="headerlink" title="大数据学习"></a>大数据学习</h1><h2 id="–idea上运行WordCount程序"><a href="#–idea上运行WordCount程序" class="headerlink" title="–idea上运行WordCount程序"></a>–idea上运行WordCount程序</h2><blockquote>
<blockquote>
<p>环境：<br>idea：ultimate 2018.1</p>
</blockquote>
</blockquote>
<p>首先打开idea<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190326111811050.png" alt><br>界面是这样的，我们新建项目，选择maven项目，project SDK选择自己的jdk根目录，直接next<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190326111904421.png" alt><br>然后是组id和工件id，自己命名，然后next<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190326112229603.png" alt><br>然后是项目名称和项目存放地址，然后finish<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190326112503174.png" alt><br>进来项目主页，右下角会有提示，我们选择右边的<code>Enable Auto-Import</code>，这个是自动给我们导入包<br>我们先设置一下maven环境<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190326113059444.png" alt><br><code>file-&gt;settings</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190326113152411.png" alt><br>输入maven到这个页面，我们要修改的是下面两个<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190327080718366.png" alt><br>第一个设置为maven安装的根目录<br>下面一个设置为<code>maven-&gt;conf-&gt;settings</code><br>然后在pom.xml文件里面添加一些代码<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190327080859204.png" alt><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;log4j&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;log4j&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.2.17&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;2.6.1&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure></p>
<p>log4j是日志打印文件，可以将mapreduce的运行日志打印在控制台，hadoop-client是hadoop客户端，然后我们在src的java文件夹新建一个类，写入wordcount代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.FileSystem;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.IntWritable;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">public class HadoopDriver &#123;</span><br><span class="line"></span><br><span class="line">    public static class HadoopMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">        private Text textKey = new Text();</span><br><span class="line">        private IntWritable count = new IntWritable();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            String[] words = value.toString().split(&quot;,&quot;);</span><br><span class="line">            for (String word : words) &#123;</span><br><span class="line">                textKey.set(word);</span><br><span class="line">                count.set(1);</span><br><span class="line">                context.write(textKey, count);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class HadoopReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">        //相同的key聚合 几种类型的key调用reduce几次</span><br><span class="line">        private IntWritable count = new IntWritable();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            int sum = 0;</span><br><span class="line">            for (IntWritable value : values) &#123;</span><br><span class="line">                sum += value.get();</span><br><span class="line">            &#125;</span><br><span class="line">            count.set(sum);</span><br><span class="line">            context.write(key, count);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">        Configuration config = new Configuration();</span><br><span class="line">        //把任务封装到job对象</span><br><span class="line">        Job job = Job.getInstance(config);</span><br><span class="line">        //</span><br><span class="line">        job.setJarByClass(HadoopDriver.class);</span><br><span class="line">        job.setMapperClass(HadoopMapper.class);</span><br><span class="line">        job.setReducerClass(HadoopReducer.class);</span><br><span class="line">        //指定map</span><br><span class="line">        // 如果map的输出和reduce输出key-value类型一致  可以不写map</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">        //指定reducer</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        //告诉hadoop集群 以什么方式读取数据  从哪里读取</span><br><span class="line">        job.setInputFormatClass(TextInputFormat.class);</span><br><span class="line">        TextInputFormat.setInputPaths(job, new Path(&quot;D:\\word.txt&quot;));</span><br><span class="line"></span><br><span class="line">        //告诉hadoop集群以什么样的方式写入数据   数据写入到哪里</span><br><span class="line">        job.setOutputFormatClass(TextOutputFormat.class);</span><br><span class="line">        Path path = new Path(&quot;D:\\wordcount&quot;);</span><br><span class="line">        FileSystem fs = FileSystem.get(config);</span><br><span class="line">        if (fs.exists(path)) &#123;</span><br><span class="line">            fs.delete(path, true);</span><br><span class="line">        &#125;</span><br><span class="line">        TextOutputFormat.setOutputPath(job, path);</span><br><span class="line">        //提交任务</span><br><span class="line">        System.exit(job.waitForCompletion(true) ? 0 : 1);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这些包，maven会帮你自动下载，你只需要导入就行，计算机必须联网<br>我们来测试一下，在D盘创建word.txt文件，里面用<code>，</code>作为分隔符写字母<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190327081453125.png" alt><br>然后我们运行wordcount程序<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190327081628077.png" alt><br>运行结果如下，运行日志被打印出来了，可以看到运行成功，没有报错，我们来检查下统计结果，打开D盘，找到wordcount文件夹<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190327081741092.png" alt><br>里面有4个文件，我们打开最后一个<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--idea%E4%B8%8A%E8%BF%90%E8%A1%8CWordCount%E7%A8%8B%E5%BA%8F/20190327081817875.png" alt><br>可以看到字母统计完成</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/iwishing/myBlog.git/2019/04/18/大数据学习--idea上运行WordCount程序/" data-id="cjumrrnkg0008kktfsc9prekb" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-大数据学习--Hive的安装与使用" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/18/大数据学习--Hive的安装与使用/" class="article-date">
  <time datetime="2019-04-18T14:03:37.505Z" itemprop="datePublished">2019-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="大数据学习"><a href="#大数据学习" class="headerlink" title="大数据学习"></a>大数据学习</h1><h2 id="–Hive的安装与使用"><a href="#–Hive的安装与使用" class="headerlink" title="–Hive的安装与使用"></a>–Hive的安装与使用</h2><blockquote>
<blockquote>
<p>环境：<br>Hive：2.3.4<br>linux：centOS 6.7<br>VM：15.0.0<br>外部环境：windows 10家庭版<br>远程工具：SecureCRT</p>
</blockquote>
</blockquote>
<h3 id="Hive的安装"><a href="#Hive的安装" class="headerlink" title="Hive的安装"></a>Hive的安装</h3><p><a href="http://mirror.bit.edu.cn/apache/hive/hive-2.3.4/" target="_blank" rel="noopener">Hive下载链接</a><br>下载完成之后，通过远程工具上传到主机里面（略）<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hive%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/20190331122600668.png" alt><br>上传成功，然后解压缩到相应的目录<br><code>tar -xcvf apache-hive-2.3.4-bin.tar.gz</code><br>解压缩完成后，我们需要配置hive的环境变量<br><code>vim /etc/profile</code><br>进入这个文件，在文件尾加入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_HOME= &lt;hive根目录&gt;</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hive%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/20190331123601806.png" alt><br>保存退出<br><code>source /etc/profile</code><br>使文件生效<br>然后验证是否配置成功<br><code>which hive</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hive%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/20190331124037464.png" alt><br>出现路径，说明配置成功<br>下一步，我们安装mysql，首先检查一下系统里有没有mysql，这一步需要网络，我们要设置虚拟机为桥接或者net模式<br><code>yum list installed|grep mysql</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hive%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/20190331125840674.png" alt><br>我的之前安装过，我们先卸载他重装一下<br>卸载<code>yum -y remove mysql.x86_64</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hive%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/20190331010028817.png" alt><br>卸载成功，重装<br><code>yum -y install mysql-server mysql mysql-devel</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hive%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/20190331010222060.png" alt><br>安装成功，我们看一下服务启动没有<br><code>service mysqld status</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hive%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/20190331010815220.png" alt><br>没有启动，我们启动一下，并且设置开机启动<br><code>chkconfig --level 35 mysqld on</code><br>然后我们先手动启动一下mysql服务<br><code>service mysqld start</code><br>通常情况下，新安装好的mysql不需要密码输入<strong>mysql</strong>就能登录，我们为了安全起见，要设置用户名和密码<br>进入/usr/bin目录，然后执行<br><code>ls|grep mysql</code><br>再执行<br><code>mysql_secure_installation</code><br>这个是给新安装的mysql配置用户名和密码的，我们设置一下<br>然后我们使用<br><code>mysql -&lt;用户名&gt; -p&lt;密码&gt;</code><br>就能登录mysql了<br>退出输入<code>exit</code>即可<br>接下来配置hive的文件，进入hive里面的conf目录<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hive%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/20190331124636570.png" alt><br>能看到hive-default.xml.template和hive-env.sh.template两个文件，我们需要拷贝然后改名字，这就是两个文件的副本，方便我们修改<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp hive-default.xml.template hive-site.xml</span><br><span class="line">cp hive-env.sh.template hive-env.sh</span><br></pre></td></tr></table></figure></p>
<p>然后我们来配置这两个文件</p>
<h4 id="hive-env-sh"><a href="#hive-env-sh" class="headerlink" title="hive-env.sh"></a>hive-env.sh</h4><p>我们只需要在里面加上hadoop的根目录就行<br><code>HADOOP_HOME=&lt;hadoop根目录&gt;</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hive%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/20190331014931333.png" alt></p>
<h4 id="hive-site-xml"><a href="#hive-site-xml" class="headerlink" title="hive-site.xml"></a>hive-site.xml</h4><p>加入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">      &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/local/hive-metastore-dir/warehouse&lt;/value&gt;</span><br><span class="line">      &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;jdbc:mysql://cbw:3306/hivedb?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;123456&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<p>其中<strong>hive.metastore.warehouse.dir</strong>和<strong>javax.jdo.option.ConnectionURL</strong>文件里面有，可用<code>/&lt;字符串&gt;</code>查找并且修改value为上面的值即可，然后修改主机名为自己的主机名<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hive%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/20190331015902175.png" alt><br>然后下载数据库驱动包<br><a href="https://dev.mysql.com/downloads/file/?id=484819" target="_blank" rel="noopener">https://dev.mysql.com/downloads/file/?id=484819</a><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hive%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/20190331020502326.png" alt><br>下载完成，上传驱动包到虚拟机<br>然后将驱动包移动到hive安装目录下的lib目录里面<br><code>mv mysql-connector /usr/hive/lib/</code><br>然后重启数据库<br><code>service mysqld restart</code><br>重新初始化元数据信息<br><code>./shematool -dbType mysql -initSchema</code></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/iwishing/myBlog.git/2019/04/18/大数据学习--Hive的安装与使用/" data-id="cjumrrnkk000akktf9fk6yrdn" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-大数据学习--Hadoop安装与配置" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/18/大数据学习--Hadoop安装与配置/" class="article-date">
  <time datetime="2019-04-18T14:03:37.495Z" itemprop="datePublished">2019-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="大数据学习"><a href="#大数据学习" class="headerlink" title="大数据学习"></a>大数据学习</h1><h2 id="–Hadoop安装与配置"><a href="#–Hadoop安装与配置" class="headerlink" title="–Hadoop安装与配置"></a>–Hadoop安装与配置</h2><blockquote>
<blockquote>
<p>环境：<br>jdk：1.8<br>hadoop：2.6.1<br>linux：centOS 6.7<br>VM：15.0.0<br>外部环境：windows 10家庭版<br>远程工具：SecureCRT</p>
</blockquote>
</blockquote>
<h3 id="1-网络环境配置"><a href="#1-网络环境配置" class="headerlink" title="1. 网络环境配置"></a>1. 网络环境配置</h3><p>因为我是处于学习阶段，所以使用vm虚拟机模拟大数据环境。设置3个服务器，选定一个作为主机。<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324110341507.png" alt><br>我选择第一个，也就是service01为主机。</p>
<h4 id="首先配置ip，将三个服务器ip设置到同一网段。"><a href="#首先配置ip，将三个服务器ip设置到同一网段。" class="headerlink" title="首先配置ip，将三个服务器ip设置到同一网段。"></a>首先配置ip，将三个服务器ip设置到同一网段。</h4><p>修改ip地址有两个方法，一个是修改文件，还有个是进入setup修改。</p>
<h5 id="通过文件修改："><a href="#通过文件修改：" class="headerlink" title="通过文件修改："></a>通过文件修改：</h5><p><code>vim /etc/sysconfig/network-scripts/ifcfg-eth8</code><br>输入以上命令进入eth8这块网卡，这个虚拟网卡是vm虚拟机自带的，还有一块eth0，我们使用哪一个都一样，只是一个名字。进入后我们可以看到以下界面：<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324111638299.png" alt><br>DEVICE=网卡名称<br>HWADDR=物理地址（硬件地址）<br>TYPE=网卡类型（可以设置成static，静态永久的）<br>UUID=是虚拟机自己设置的<br>ONBOOT=是否开机启动<br>IPADDR=ip地址，也就是我们要修改的<br>NETMASK=子网掩码<br>我们需要修改ip地址，将它的地址和我们自己的电脑，虚拟机的ip这3者的ip设置到同一网段内，另外两台同理，一样设置。</p>
<h5 id="通过setup界面修改："><a href="#通过setup界面修改：" class="headerlink" title="通过setup界面修改："></a>通过setup界面修改：</h5><p>直接输入<br><code>setup</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324112315705.png" alt><br>进入以上界面，选择第四个，network configuration<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324112414087.png" alt><br>选择第一个<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324112431091.png" alt><br>可以看到我们的eth8这块网卡，选择它<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324112457782.png" alt><br>这里我们可以直接修改网卡名和ip地址，修改完成后，save&amp;quit，然后执行<br><code>service network restart</code><br>重启网络服务，再次输入<br><code>ifconfig</code><br>查看，可以看到，ip已经修改了<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324112731303.png" alt></p>
<h4 id="下一步修改主机名，不然三个服务器的主机名默认都是root，这对后来设置域名映射时会很麻烦。"><a href="#下一步修改主机名，不然三个服务器的主机名默认都是root，这对后来设置域名映射时会很麻烦。" class="headerlink" title="下一步修改主机名，不然三个服务器的主机名默认都是root，这对后来设置域名映射时会很麻烦。"></a>下一步修改主机名，不然三个服务器的主机名默认都是root，这对后来设置域名映射时会很麻烦。</h4><p>我们输入下面的命令，进入network文件。<br><code>vim /etc/sysconfig/network</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324110702179.png" alt><br>里面的HOSTNAME就是你的主机名，默认是root，修改成自己的，然后ESC，shift+:,wq保存退出<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324110932243.png" alt><br>可以看到，主机名改变了</p>
<h3 id="2-域名映射，ssh免登陆设置"><a href="#2-域名映射，ssh免登陆设置" class="headerlink" title="2. 域名映射，ssh免登陆设置"></a>2. 域名映射，ssh免登陆设置</h3><p>为了以后使用ssh登录其他服务器方便，我们要做域名映射，不然，每次都是输入一串ip地址，太麻烦，我们要在hosts文件里面修改域名映射，按照上面的教程，我们应该已经将3台服务器的主机名都设置好了，我的是cbw，cbw1，cbw2.<br>输入<br><code>vim /etc/hosts</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324113356993.png" alt><br>进入hosts文件，直接换行，写ip地址，空格，主机名，3台服务器都设置，然后保存退出<br>使用ping测试一下是否能通。<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324113859060.png" alt><br>可以看到，我们直接ping名字也能ping通，说明设置成功。其他几台服务器一样设置，为了方便，我们采用分发的方式，直接将这个文件分发给另外两台服务器。<br><code>scp /etc/hosts cbw1:/etc/hosts</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324114141319.png" alt><br>分发成功，cbw2同理，我们去看看另一台服务器是否能ping域名ping通。<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324114249976.png" alt><br>可以看到，我通过cbw1直接ping主机cbw，是可以ping通的，说明文件分发成功，cbw2也通过相同的方式分发就行。<br>ssh免登陆设置：<br>我们使用ssh远程登录其他服务器的时候要输入密码，而因为hadoop的原因，有很多时候要多次登录其他服务器，每次都输入密码的话，很浪费时间和操作，而且我们使用hadoop的时候基本没有什么安全隐患，所有没必要设置每次都登录输入密码，这样会让操作变繁琐，因此我们要设置ssh免登陆。<br>先在root目录下查看是否有.ssh文件夹，如果没有的话就新建一个。<br>然后输入以下命令<br><code>ssh-keygen</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324115258041.png" alt><br>然后一直回车，直到出现一个图案<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324115350198.png" alt><br>这个时候代表获取密钥成功了，下一步，分发密钥给其他服务器<br><code>ssh-copy-id cbw1</code><br>然后它会提示你输入密码，输入密码之后就代表成功了，下次使用ssh命令进入cbw1时是不用输入密码的，同理，cbw2也配置一下，ssh免登陆设置成功。</p>
<h3 id="3-服务器配置jdk环境"><a href="#3-服务器配置jdk环境" class="headerlink" title="3. 服务器配置jdk环境"></a>3. 服务器配置jdk环境</h3><blockquote>
<blockquote>
<p>以下所说的jdk都是你自己下载的jdk压缩包名，或者解压后的jdk文件夹的名字，我自己的改名叫jdk，方便修改其他东西</p>
</blockquote>
</blockquote>
<p>首先下载好jdk<br><a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">下载地址</a><br>要安装一种远程连接工具，xshell或secureCRT都行，我使用的是secureCRT，连接好主机后，使用alt+p调出sftp窗口<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324121414887.png" alt><br><code>put &lt;文件路径&gt;</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324121526986.png" alt><br>回车，上传jdk到服务器，然后查看root目录下，文件是否上传成功<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324121618909.png" alt><br>可以看到，jdk上传成功<br>再将jdk移动到/usr/文件夹下面<br><code>mv jdk /usr/</code><br>然后解压jdk<br><code>tar -xvzf jdk</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324122335603.png" alt><br>解压成功，可以看到有很多jar包。<br>接下来就是配置环境变量了，进入/etc/profile/文件<br><code>vim /etc/profile</code><br>跳到文件末尾，输入以下内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/jdk</span><br><span class="line">export JRE_HOME=/usr/jdk/jre</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export CLASSPATH=.$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324122517876.png" alt><br>然后出去输入<br><code>source /etc/profile</code><br>刷新文件并保存，再输入<br><code>java -version</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324122947439.png" alt><br>如果出现以上信息，说明jdk环境已经搭建完毕<br>然后，我们使用scp命令，将jdk和环境配置文件分发到其他的两台服务器上面<br><code>scp -r /usr/jdk/ cbw1:/usr/jdk/</code><br><code>scp /etc/profile/ cbw1:/etc/profile/</code><br>cbw2同理，然后去到另外两台服务器source一下文件,重新加载并生效<br><code>source /etc/profile</code><br>此时，3台服务器的jdk都已经配置完毕</p>
<h3 id="4-服务器配置Hadoop环境"><a href="#4-服务器配置Hadoop环境" class="headerlink" title="4. 服务器配置Hadoop环境"></a>4. 服务器配置Hadoop环境</h3><p><a href="https://archive.apache.org/dist/hadoop/common/" target="_blank" rel="noopener">hadoop下载地址</a><br>找到相应版本下载即可<br>安装hadoop与jdk同理，上传hadoop压缩包，然后解压，然后放到/usr/里面，开始配置环境变量，进入/etc/profile/文件<br><code>vim /etc/profile</code><br>跳到文件末尾，输入以下内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/usr/hadoop-2.6.1</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin</span><br></pre></td></tr></table></figure></p>
<p><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324102915221.png" alt><br>然后出去输入<br><code>source /etc/profile</code><br>刷新文件并保存，再输入<br><code>hadoop version</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324103209122.png" alt><br>如果出现以上画面，说明环境配置完毕</p>
<h3 id="5-Hadoop文件配置"><a href="#5-Hadoop文件配置" class="headerlink" title="5. Hadoop文件配置"></a>5. Hadoop文件配置</h3><p><code>cd /usr/hadoop2.6.1/etc/hadoop/</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324112142817.png" alt><br>进入这个文件夹，我们需要配置6个文件：</p>
<h4 id="hadoop-env-xml"><a href="#hadoop-env-xml" class="headerlink" title="hadoop-env.xml"></a>hadoop-env.xml</h4><p>这个文件用来配置jdk的根路径<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324111543938.png" alt><br><code>export JAVA_HOME=/usr/jdk</code><br>在文件末尾加入jdk的路径，保存退出</p>
<h4 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h4><p>输入<br><code>vim core-site.xml</code><br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324113841647.png" alt><br>文件内容如上，我们使用默认的文件系统<strong>fs.defaultFS</strong>，我们需要修改的是<strong>fs.defaultFS</strong>的<strong>value</strong>，这个值是告诉文件系统他的老大在哪台服务器启动，也就是主机，我的自然是cbw，后面的<strong>9000</strong>是端口。下面的<strong>hadoop.tmp.dir</strong>是告诉系统，hadoop的源文件存放在哪个目录下，<strong>value</strong>就是我设置的目录，默认是在hadoop根目录下的<strong>hdpdata</strong>文件夹，如果没有这个文件夹，hdfs在格式化的时候会去自动创建这个文件夹。                                                                                 </p>
<h4 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h4><p>这个文件是配置上传文件的<strong>blocksize</strong>副本数的<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324114117205.png" alt><br><strong>value</strong>设置为多少，block的副本数就是多少，如果不设置，它默认是3个，这里我们设置为2个</p>
<h4 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h4><p>这个是配置mapreduce所使用的框架<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324114506643.png" alt><br>我们使用yarn框架</p>
<h4 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h4><p>这个文件配置yarn的主机和nodemanager的服务<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324114620907.png" alt><br><strong>yarn</strong>的主机我们当然选择cbw，然后nodemanager的<strong>value</strong>我们写mapreduce_shuffle</p>
<h4 id="slaves"><a href="#slaves" class="headerlink" title="slaves"></a>slaves</h4><p>这个文件时配置所有服务器的<br><img src="https://cbw-1258890494.cos.ap-chengdu.myqcloud.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0--Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/20190324114941015.png" alt><br>我们加上所有的服务器域名<br>到这里，需要配置的文件已经全部完成<br>然后格式化<strong>hdfs</strong><br><code>hdfs namenode -format</code><br>格式化完毕，同理，我们要将hadoop文件夹分发给其他服务器，还有环境文件也要分发<br><code>scp -r /usr/hadoop2.6.1 cbw1:/usr/hadoop2.6.1</code><br><code>scp /etc/profile cbw1:/etc/profile</code><br>cbw2同理<br>然后别忘记保存生效<br><code>source /etc/profile</code><br>到这一步hadoop的配置就完成了</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/iwishing/myBlog.git/2019/04/18/大数据学习--Hadoop安装与配置/" data-id="cjumrrnl6000ekktfscxqtkcj" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-大数据学习--HA" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/18/大数据学习--HA/" class="article-date">
  <time datetime="2019-04-18T14:03:37.484Z" itemprop="datePublished">2019-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="大数据学习"><a href="#大数据学习" class="headerlink" title="大数据学习"></a>大数据学习</h1><h2 id="–HA"><a href="#–HA" class="headerlink" title="–HA"></a>–HA</h2><blockquote>
<blockquote>
<p>环境</p>
</blockquote>
</blockquote>
<h3 id="HA简介"><a href="#HA简介" class="headerlink" title="HA简介"></a>HA简介</h3><h3 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/iwishing/myBlog.git/2019/04/18/大数据学习--HA/" data-id="cjumrrnkf0007kktfb2haddgn" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Linux学习随笔" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/18/Linux学习随笔/" class="article-date">
  <time datetime="2019-04-18T14:03:37.476Z" itemprop="datePublished">2019-04-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="linux学习随笔"><a href="#linux学习随笔" class="headerlink" title="linux学习随笔"></a>linux学习随笔</h1><blockquote>
<blockquote>
<p>环境：<br>系统：centos 6.3<br>VM：15.0.0<br>外部环境：windows 10家庭版<br>远程工具：SecureCRT</p>
</blockquote>
</blockquote>
<h3 id="删除用户"><a href="#删除用户" class="headerlink" title="删除用户"></a>删除用户</h3><p>命令<br><code>userdel &lt;用户名&gt;</code><br>今天做实验的时候，发现删除不了用户，原因可能是之前登录过，和root之间切来切去，虽然xiaoming这个用户的远程什么的都断开了，但是有线程还在运行<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/Linux%E5%AD%A6%E4%B9%A0%E9%9A%8F%E7%AC%94/20190404011814349.png" alt><br>这样我们可以强制删除<br><code>userdel -f &lt;用户名&gt;</code><br>这样可以强制删除，即使这个用户还在登录，或者其他用户在使用这个用户的home文件夹<br><code>userdel -fr &lt;用户名&gt;</code><br>加上<strong>r</strong>选项，可以在删除的时候讲home文件夹下面的用户目录一起删除<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/Linux%E5%AD%A6%E4%B9%A0%E9%9A%8F%E7%AC%94/20190404012048561.png" alt><br>home目录的xiaoming也没了<br><img src="http://cbw-1258890494.cos.ap-chengdu.myqcloud.com/Linux%E5%AD%A6%E4%B9%A0%E9%9A%8F%E7%AC%94/20190404012119519.png" alt></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/iwishing/myBlog.git/2019/04/18/Linux学习随笔/" data-id="cjumrrnk90003kktfsme2zai2" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/04/18/小科普/为什么判断闰年不能单单看这一年是否为4的倍数/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/04/18/大数据学习--小实验/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/04/18/大数据学习--zookeeper/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/04/18/大数据学习--MapReduce程序编写/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/04/18/大数据学习--idea与maven的安装与配置/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Iwishing<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>